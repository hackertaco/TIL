# Abstract

Uber의 수많은 데이터를 실시간으로 처리하는 전반적인 아키텍처를 소개하면서도, 그 아키텍처의 도전 과제 3가지를 언급하고, 또 우버가 채택한 오픈소스 프로젝트와 그를 어떻게 우버에 맞게 녹여 사용하고 있는지 설명

# Introduction

많은 실시간 데이터들이 우버의 데이터 센터에서 만들어진다.
그리고 이러한 데이터를 처리하는 것은 전방위적으로 영향을 미치고 상당히 중요하다.

아래의 세가지 영역에서 데이터 처리가 필요하다.

1. 메시지 플랫폼
2. 메세지들을 병렬 처리하는 스트림 프로세싱
3. OLAP (데이터 분석)

그리고 이 세가지 영역은 데이터 스케일링을 하는 데 있어 각각 세가지 고민거리를 안고 있다.

1. 데이터 범위 처리: 실시간 데이터량은 계속 증가하고, 여러 지역으로 나누어 데이터를 다루는데, 고객이 기대하는 범위 내에서 이러한 데이터 처리를 할 수 있어야한다.
2. 사용례 범위 처리: 다양한 영역에서의 비즈니스가 생기고, 그만큼 다양한 요구사항이 생긴다. 각 요구사항들을 해결하기 위하여 서로다른 우선순위가 있고, 그 우선순위에 따라 일처리를 진행해야 한다.
3. 사용자 처리: 다양한 이해관계자들은 기술적 기반이 있는 사람이 있고 없는 사람들도 있다. 이들 각각에 맞게 일처리를 해야한다.

결과적으로 하나의 통일된 플랫폼을 만들면서도, 여러 케이스를 포괄할 수 있어야한다.
이러한 고민거리를 해결하기위해 오픈 소스를 사용했다.
이러한 오픈소스 사용은 개발 속도, 비용 감소 측면에서 도움이 된다.

# Requirements

여러 방면으로 실시간 데이터를 사용하게 되는데, 각각은 여러 요구사항들이 있다.

1. 일관성
   재무적 대시보드 사용은 어떤 지역에서나 일정한 데이터를 요한다.
   지역과 관계없이 데이터 loss가 있어서는 안된다.

2. 사용 가능성
   언제든지 원할 때 데이터를 사용할 수 있어야한다.

3. 데이터 신선도
   초단위의 데이터 신선도가 요구된다.

4. 검색 시간
   검색에 너무 많은 시간이 소요되면 안된다.

5. 확장성
   계속해서 데이터들은 증가하게 되는데, 이를 따로 사용자가 프로세싱하는 데 시간을 들일 필요없이 매끄럽게 확장하는 것은 중요하다.

6. 비용
   높은 운영 효율으로 낮은 데이터 운용 비용을 이룩해야한다.

7. 유연성
   다양한 이해관계자 그룹에 맞게 선언적이고 프로그래머틱한 인터페이스를 제공해야한다.
   push-based, pull-based 모델 선택과 같이 상황에 따라서 다른 모델을 선택할 수 있다.

이 모든 요구사항을 보장하는 것은 불가능하다.
데이터 일관성이 있으면서도 데이터 신선도를 맞추는 것을 보장하긴 어렵다.
비지니스 영향을 최소화하기위하여, 상황에 맞게 우선순위를 정하는 것이 중요하다.

# Abstractions

실시간 데이터를 처리하는 논리적인 개념에서의 요소들 설명
**1) Storage**
일반적인 객체나, blob 스토리지 인터페이스. 데이터 일관성 보장

**2) Stream**
publish-subscribe interface 제공
데이터 읽고 쓰는데 지연이 있으면 안된다.
at least once와 파티션이 최소 조건

**3) Compute**
임의로 스트림 혹은 스토리지 레이어를 처리하는 것
스트림 처리시, 각각의 이벤트에 발생
스토리지 처리시, 일괄 처리
이는 스트림 혹은 스토리지 처리시 어떤 같거나 다른 기술을 사용할 수 있다는 점에서 중요하다.
같은 기술을 사용하게 된다면, 더 간단히 추상화를 시킬 수 있지만 실행하기는 더 복잡하다. 운영적 오버헤드가 발생간다.
반면에, 서로 다른 기술은 더 높은 레이어가 그에 맞게 각각 처리할 수 있게한다.

최소 조건: at least once semantics between data source and sink

**4) OLAP**
스트림이나 스토리지로부터 오는 데이터를 제한적으로 쿼리할 수 있다.
최소 조건: 서로 다른 데이터 소스로부터 데이터 처리 at least once semantics

**5) SQL**
OLAP를 기반으로 Full 쿼리, 처리 가능
Compute Layer와 함께 사용할시, sql문은 compute function에 컴파일된다.
OLAP layer와 함께 사용시, 제한된 쿼리위에서 추가적인 처리를 하게된다. ex) join문 사용
최소 조건: ANSI SQL에 가까운 SQL 언어 사용

**5) API**
스트림이나 compute function 을 구체화하는데 있어 SQL 인터페이스로는 충분하지 않은 경우

**6) Metadata**
메타데이터 관리하기위한 인터페이스
최소조건: 메타데이터 버전, 서로 양립 가능한지 체크

# System Overview

위의 요소들에 맞는 오픈 소스 시스템 설명.

### 스트리밍 스토리지를 위한 카프카

카프카는 유명한 분산 이벤트 스트리밍 시스템이다.
다른 것에 비하여 퍼포먼스 적으로, 운영 단순함, 생태계 등에서 최고라 선택하게 되었다.
우버에서는 매일 수조의 메세지와 페타바이트 데이터가 발생하는데, 카프카는 서로 다른 워크플로우에 이 데이터를 스트림한다.

1. Cluster Federation
   클러스터 에러 혹은 데이터 가용성을 향상시키기위해, 카프카 클러스터 셋업 처리를 하였다.
   어디에 클러스터링해야할지 고민할 필요가 없다.
   더불어 클러스터가 꽉 차면 스케일링도 할 수 있다.
   여러 서비스들이 많은데, 수동으로 유저를 옮길 필요도 없다.

2. Dead Letter queue
   몇몇 메세지가 처리되지않을 때가 있다. 카프카의 모델 아래선, 그를 없애거나 재시도 하는 방법이 있다.
   우버는 Dead Letter queue로 이를 해결했다.
   dead letter topic으로 옮겨 문제생긴 메세지를 유저가 처리하게 한다.

3. Consumer Proxy
   기존 카프카에서 Consumer Library를 제공해 client management를 돕지만, 우버는 너무 큰 회사이므로,
   여러 프로그래밍 언어 사용하는 상황도 보완하고, 여러 어플리케이션이 돌아가는 상황도 고려해야한다.
   따라서 우버는 프록시 레이어를 만들어 카프카에서 오는 메세지들을 소비하고 gRPC로 dispatch한다.
   이렇게 하면, 에러 핸들링이 수월하고, 기존 메세지 폴링 매커니즘에서 push-based로 전환이 가능하다. 높은 병렬성을 이룰 수 있다.

4. Cross-cluster Replication
   아무래도 큰 스케일로 카프카를 이용하다보니, 서로 다른 데이터 센터에서 여러 클러스터를 사용하게 되었다.
   이럴 경우, 전체적인 시점에서 다양한 사용례를 위해 데이터를 보아야 하고, 카프카가 많은 클러스터를 수용하고 데이터 센터의 failure를 대응하기 위해 복제되된다는 점에서,
   카프카 클러스터 복제가 필요하다.

uReplicator를 만들어 카프카 클러스터 사이를 오가는 복제물을 만들었다.
내부에는 리밸런싱 알고리즘이 있어, 리밸런싱 중에는 파티션 영향을 최소화한다. 또한 트래픽이 많아도 동적으로 로드를 조절할 수 있다.

더불어 자체적으로 감사하는 서비스도 만들었다. Chaperone이라는 서비스는 중요한 통계를 모아 비교하고 불일치가 발생하면 알람을 준다.

이러한 개선으로, 실시간으로 카프카 기반 위에서 스트리밍과 메세징 기능을 안정적으로 구현했다.

### 스트림 처리를 위한 Flink

모든 실시간 데이터를 카프카로 처리하기위해 우리는 스트림 처리 플랫폼을 플링크 기반으로 만들었다.
플링크는 high-throughput, low-latency를 자랑한다.
이 오픈소스는 많은 양의 업무를 처리하는 데 있어 충분히 안정적이고, 스케일하기가 좋다. 또, 사용하는 많은 사람들이 있다.

다른 것과 비교해봐도, 플링크가 우위에 있었다.

우버에서는, 고객들이 마주하는 프로덕을 유용하게 사용하고, 대시보드 용으로 플링크를 사용한다.
스트림 처리 로직은 SQL dialect나 API들로 표현된다.
SQL은 서로 다른 카테고리의 이해관계자들에게 사용된다. API는 더 세세히 처리하는 엔지니어용이다.

우버는 이 플링크에 두가지 개선을 만들었다.

1. SQL을 통한 분석 어플리케이션 생성
   FlinkSQL이라는 것을 만들었다.
   SQL프로세서가 쿼리들을 플링크 어플리케이션에 컴파일하고, 이해관계자들이 비지니스 로직만 신경쓰게끔 한다.
   내부적으로는, input SQL 쿼리를 플링크에 옮겨주는 로직을 만들었다.
   그러나 운영적으로 여러 어려움이 있었다.

- 자원 예측과 자동 스케일링
  할당된 메모리나 CPU와 같은 자원 설정은 중요하다.
  클러스터 이용을 최대화하기 위해, 지속적인 모니터링과 카비지 콜릭션, 오토 스케일링이 필요하다.
  플링크는 상태가 없기 때문이다.

- 활동 모니터링과 자동 실패 회복
  사용자는 플링크가 어떤 것을 하고 있는지 모르기 때문에, 플랫폼이 모니터해야한다.
  이를 위해 자동으로 이를 확인하는 컴포넌트를 만들었다.
  FlinkSQL은 프레스토와 같은 일괄처리 SQL시스템과는 다른 문법을 가지고 있다.
  이는 일괄처리하는 게 아니라, 지속으로 들어오는 데이터를 처리한다.

2. 배포, 관리, 운영을 위한 통일된 아키텍쳐 생성
   스트림 처리를 위하여 두개의 플랫폼을 만들었으므로, 하나의 통일된 아키텍처를 만들었다.

- 플랫폼 레이어
  비지니스 로직과 결합을 관리한다.
  특정 비지니스 로직을 기준이되는 플링크 잡으로 바꿔준다.
- 업무 관리 레이어
  플링크의 처리 사이클을 관리한다.
  통일된 API를 제공하고, 메타데이터 관리나 상태 체크포인트를 포함하는 업무 정보들을 유지한다.
  프록시 레이어로서 작용하기도 한다.
- 인프라 레이어
  물리적인 자원 제공, 스토리지와 compute 클러스터 포함

## OLAP를 위한 PINOT

Pinot은 낮은 처리시간을 자랑하는 OLAP 오픈소스 시스템이다. 컬럼 지향 DBMS로, 빠른 인덱싱을 제공한다.
scatter-gather-merge 접근으로 큰 테이블을 검색한다.
Pinot은 더 적은 메모리, 디스크 소모를 적게 하여 택했다.

이는 실시간 분석하는 데 큰 도움을 준다.
또한 많은 백서비스에서도 분석 쿼리 처리를 한다.

우버는 Pinot에 여러 기여를 했는데

1. Upsert 기능
   우버에 많이 사용되는 기능이다.
   실시간으로 OLAP 스토어에 업데이트가 가능하다.
   그러나 같은 메인 키에서 장소를 트래킹하는 것이 어려웠다.
   이를 해결하기위해 인풋 스트림을 여러 파티션으로 나누고, 처리를 위해 각 파티션을 한 노드에 분산했다.
   그 전에 쿼리 결과의 무결성을 위해 같은 노드에 같은 파티션을 두는 쿼리로 새로운 라우팅 전략을 제시했다.

2. Full SQL Support
   Pinot은 빠른 검색을 가능하게 하는 OLAP 시스템이다.
   그러나, SQL Feature가 좀 부족하다. 그래서 Presto와 결합시켰다.
   Presto는 쿼리 엔진으로서 작용하는데, 복잡한 쿼리를 가능케하는데 있어 Presto의 유연함과 Pinot의 초단위 데이터 신선도 결합은 상당히 잘 운용되었다.

3. 데이터 생태계 남은 것끼리 결합
   개발속도와 생산성을 유지하는 게 중요한 큰 회사에서, Pinot과 다른 데이터 생태계를 결합하는 데 시간을 많이 소요했다.
   FlinkSQL과 결합해 간단히 SQL문 변형을 시켜 Pinot에 푸쉬되게 만들거나, 우버의 업무관리 시스템에 일부 반영되어 Pinot 오프라인 테이블을 만드는 등이 그에 속한다.

4. 세그먼트 원복
   원래의 Pinot 디자인은 분리된 스토어나 외부 아카이브에 의존하게끔 설계되었다.
   실시간 데이터 처리하는 동안, 완성된 세그먼트들은 세그먼트 스토어에 추가되어야 했다.

   그 이유는 고장이 날 가능성을 보완하기 위함이었다. 근데 그러한 백업은 하나의 컨트롤러에서 진행되어, 보틀넥이 일어났다. 데이터 신선도가 떨어지는 것도 문제였다.

   게다가, 세그먼트 스토어 문제는 모든 데이터 처리를 멈추게했다.
   따라서 비동기적으로 이를 처리하도록 했다. 중앙 집중식에서 동료간 스키마로 바꾸었다.

   이러한 개선들로, 수백 테라바이트 데이터를 수십 기가바이트로 바꿀 수 있었다. 동시에 쿼리 속도도 훨씬 빨라졌다.

## 아카이브 스토어로서의 HDFS

장기 스토어로서 HDFS를 사용한다. 여러 데이터들과 로그들을 장기적으로 보관한다.
또한 다른 플랫폼들이 지속적인 스토리지로 사용하기도 한다. (스냅샷 용도)

## 상호적 쿼리로서의 Presto

Hive와 같은 분산 SQL쿼리 엔진 생태계가 많이 사용되었다. 이는 데이터 유연성을 중시한 것으로, 데이터 처리나 혹은 속도와는 관계가 없었다. 최근에는, 이런 부분들도 중요하게 여겨져 Presto를 도입했다.
presto는 대규모 병렬 컴퓨터 엔진을 도입하여, 빠르게 분석 쿼리를 실행할 수 있다.
그러면서도, 상당히 유연하고 확장성이 있다. 다른 I/O 인터페이스 간 Connector API를 지원한다.

# 사용례 분석

실시간 데이터 유스케이스들을 나열하고, 각각의 장단점 언급

## 분석 어플리케이션: Surge Pricing

수요공급 균형을 맞추는 Surge Pricing 정책을 구현하기위해, 스트리밍 데이터를 카프카에서 가져와, 복잡한 머신 러닝을 Flink로 돌리고, 그를 sink에 저장한다.
Surge Pricing은 데이터 신선도와 가용성을 중시한다. 대신 중간에 데이터 로스가 일어나는 부분을 막기는 어렵다.

## 대시보드: 우버이츠 매니저들이 사용하는

신선한 데이터와 빠른 쿼리속도가 필요. 유연성은 상대적으로 필요가 없다.
Pinot으로 사전 데이터 결합도 인덱싱을 처리하고, Flink로 결합 필터링을 하며, 속도를 줄인다.
이런 사전 프로세싱처리를 통해, 유연성은 떨어지더라도 쿼리 속도는 줄일 수 있다.
일반적으로는, 플링크로 변환하는 시간과 pinot으로 쿼리하는 시간 사이에는 트레이드오프가 있다.
따라서 플링크로 사전 처리를 함으로서 데이터 서빙 시간을 줄인다.

## 머신러닝: 실시간 예측 모니터링

ML 모델 품질을 위하여, 정확한 데이터를 지속적으로 보내는 것을 감시해야한다.
그를 위해, 모니터링 파이프라인이 만들어졌다.
이를 위하여 확장성이 중요하다. 데이터량이 많고, 데이터 카디날리티가 크기 때문이다.
플링크의 횡적 확장성 덕분에, 이 큰 스트리밍 역할을 할 수 있었다.
쿼리 퍼포먼스 향상을 위해, pinot 테이블에서처럼 사전 aggregation을 실행한다.

## 우버이츠 운영 자동화

분석쿼리를 실시간으로 실행하는 방법이 필요했다.
규칙 중심으로 자동화 프레임워크 쿼리 대량생산을 해야했고, 코로나 위험과 서로 다른 지역적인 위치를 가진 특징이 있었기에 이건 필요했다. 프레스토로 모집단을 식별할 수 있었고, pinot으로 실시간 데이터를 가져와 업무 자동화에 쿼리를 주입했다.

이는 pinot을 이용해 필요한 지역에 통계를 만들어낼 수 있었고 알림을 바로 해준다.
말할 필요도없이, 이는 굉장히 믿을만해야하며 확장성이있어야한다. 왜냐하면 비지니스와 손님들의 건강이 결부된 문제였기 때문이다. Pinot과 presto, Flink는 피크 시간대에 이를 잘 수행해주었다.

# 액티브 전략

비지니스 회복과 지속성을 제공하는 것은 굉장히 중요하다.
문제가 발생했을 때 비지니스 영향을 최소화해야한다.
우버에서는, 다양한 지역 전략을 사용해서 한쪽이 고장났을 때, 다른 쪽이 보완한다.
우버의 많은 사용례는 카프카 액티브-액티브 셋업에 많이 의존한다.
카프카에 이벤트들이 다 들어가고, 그것은 플링크를 통해 처리된다. 각각의 지역에서는 update service 인스턴스가 있고 그 중 하나는 주된 것으로 설정된다. 주된 지역의 update service는 결과값을 액티브-액티브 데이터베이스에 저장한다.
문제가 발생하면 액티브-액티브 서비스는 다른 지역을 primary로 설정한다.
플링크 잡이 상당히 크기 때문에 동기화하기가 어렵다. 따라서 각 지역마다 독립적으로 실행돼야한다.
각 지역마다 불필요하게 파이프라인을 돌리고 있게되므로 굉장히 강하게 처리하는 방법이라 할 수 있다.

다른 방법은 액티브-패시브 모드이다. 하나의 지역이 primary로 설정되고, 그들만이 데이터를 처리한다.
문제가 생기면 서비스는 다른 지역으로 옮겨간다. 그러한 액티브-패시브 모드는 비용처리 문제와 같은 강항 동시성이 필요할 때 사용된다. 이 액티브-패시브모드는 지역 간 동기화 문제를 해결해야한다. 왜냐면 데이터 loss가 있어서는 안되기 때문이다. uReplicator가 원천 클러스터를 복재할 때, 일시적으로 시작점을 액티브-액티브 데이터베이스에 체크한다. 그사이에, 시작점 싱크 작업을 액티브-패시브 소비자들도 진행한다.
따라서 문제가 생겼을 때, 마지막으로 동기화된 오프셋을 소비자들이 체크한다.

# Backfill

데이터 테스팅을 하거나, 새로운 머신러닝 모델 학습을 위해, 버그가 이미 처리된 데이터에 만들어졌을 때, 혹은 오래된 데이터 처리를 다시해야하는 변화가 일어날 때 시간을 돌려 되풀이하고 스트림 데이터를 다시 처리하고자 하는 니즈가 있다.

큰 데이터 처리를 하는 경우 이러한 문제는 언제든지 일어난다.
람다나 카파 아키텍쳐가 제안되었지만, 제한점이 있다.
람다는 하나는 일괄처리, 하나는 스트림 처리방법을 사용하는데, 유지에서나 동시성에서나 이슈가 있다.
카파 아키텍쳐는 같은 스트리밍 코드를 실시간으로 사용한다는 점에서 그 문제는 해결하지만, 굉장히 긴 데이터 리텐션을 요구하고 데이터 처리가 효율적이지 않다.

따라서, 플링크를 통해 backfill처리를 쉽게 하였다.

- SQL based
  실시간, 오프라인 데이터 모두에 같은 sql쿼리를 처리하는 기능을 추가했다.
  이 경우 flinkSQL컴파일러가 서로 다른 플링크 잡으로 번역해주엇다. : 하나는 데이터스트림 api, 하는 데이터셋api

- api based
  이는 카파플러스라고 명명되었다. 스트림 처리 로직을 재사용하면서도 오프라인 데이터셋에서부터 데이터를 읽어올 수 있다. 이는 효과적으로 같은 코드로 스트리밍과 배치 데이터를 처리할 수 있다.

# 관련된 작업

관련된 수많은 시스템들이있다.

1. 메세징 시스템
   카프카만한 메세징 시스템이 없다. 생태계 적으로나, 시스템 퍼포먼스 적으로나, 기능적으로나!

2. 스트림 프로세싱 시스템
   높은 확장성 스트림 프로세싱 시스템은 최근 몇년간 많은 시스템들을 만드는 데 기여했다.
   확장성 미션 말고도 효율성이나 장애 허용 시스템 말고도 중요한 이슈는 스트리밍과 일괄처리 프로세싱의 통합이다.

플링크는 일괄처리를 지원하는 쪽으로 확장한다.

3. 실시간 OLAP 시스템
   pinot처럼 처리된 스트림을 잠시 보관하거나, 효율적인 컬럼 스캔을 위해 컬럼 스토어를 이용하는 등을 통해 OLAP를 구현한다. 사전에 집계된 데이터를 통하여 속도를 빠르게 하기도 한다. 그런데, 이런 것은 유연함에 도움이 안된다.

처리와 분석 프로세싱을 통합하는데 있어 HTAP데이터베이스가 있는데, 운영적인 로드를 극복하면서도 분석쿼리를 처리해야하는 문제가 있다.

4. SQL 시스템
   많은 데이터 셋을 쿼리하는 SQL 시스템이 많이 있는데, 최근에는 실시간 데이터도 쿼리할 수 있게끔 발전했다.
   우리는 Presto를 선택해 유연하고도 확장성있어 서로 다른 데이터베이스와도 연계가 가능하다.
   실시간 데이터 인프라는 처리데이터를 연계하고, 만들어진 스트리밍데이터를 바로 이용한다.

# Lesson Learned

1. 오픈소스 도입
   빠르게 개발하기 위하여 오픈소스를 도입했다.
   그러나 그럼에도 불구하고 많은 해결할 문제가 잇었다. 우버에 맞게 그를 적용해야했다.
   카프카의 경우 우리가 쓰는 4개의 언어와 함께 RESTful하게끔 만들어야했다.
   우리만의 에러 처리를 추가해야했다.
   더불어 Pinot에는 여러 유저들을 고령해 Full SQL층을 만들어야했고 플링크를 통해 매끄럽게 Backfill처리를 하였다.

2. 빠른 개발 시스템
   아키텍쳐는 비즈니스 요구에 맞게 빠르게 발전되어야한다. 그를 위해 빠른 개발 시스템이 필요하다.
   클라이언트 사이드에서는, 대규모 어플리케이션을 구축해야한다.
   thin client가 필요하다.
   언어 강화가 필요하다.

서버 사이드에서는 인프라를 CICD와 함께 결합했다.

3. 운영과 모니터링을 쉽게 하기
   운영 자동화가 비지니스 성장을 위해서는 필수적이다.

4. 온보딩과 디버깅을 쉽게 하기
   작은 개발팀에서는 자동화가 필수다.

- 데이터 회복
  메타데이터를 중앙집중화하여 실시간, 오프라인 시스템 사이 데이터셋을 찾기 쉽게했다.

- 데이터 감시
비지니스 이벤트들은 계속 감시되고있고, 그를 메타데이터로 라벨링한다. 

- 매끄러운 온보딩
자동으로 프로비저닝되어, Flink and Pinot pipelines을 자동으로 생성할 수 있다. 

# 결론
실시간 데이터 인프라는 유연성과 스케일에 잇어서 최적화되었다. 
오픈소스 도입으로 비용을 줄였다. 이 결과 세가지 측면에서의 문제를 해결했다.

1. 스케일링 데이타
카트카를 통하여 강한 기반을 만들었고 이를 통하여 플링크와 PINOT 데이터 파이프라인을 조율했다. 
플링크 자동화 작업은 낮은 운영오버헤드를 도우며 증진시켰다. 

2. 스케일링 사용례
개별 기술에 대한 유연성을 증진시켰다. 로깅에서부터 금융 데이터까지 넓은 스펙트럼의 데이터를 서빙했다.
Pinot은 낮은 쿼리속도를 제공했고 동시에 프레스토 결합을 통해 실시간 데이터 처리를 가능케했다. 
이 모두는 요구사항에 맞게 조정되었다.

3. 유저 스케일링
유저 코스트를 줄였다. FlinkSQL로 SQL 기본지식만 있으면 파이프라인 작업을 하게 만들었고, Pinot 사이 쿼리를 가능하게 했다. 버튼 하나로  백필링을 가능케했고, 이는 계층형 스토리지같은 미래 최적화를 실행하고 기술발전을 하는데에 확장성을 주었다.
