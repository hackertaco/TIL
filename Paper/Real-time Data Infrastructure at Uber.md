# Abstract

Uber의 수많은 데이터를 실시간으로 처리하는 전반적인 아키텍처를 소개하면서도, 그 아키텍처의 도전 과제 3가지를 언급하고, 또 우버가 채택한 오픈소스 프로젝트와 그를 어떻게 우버에 맞게 녹여 사용하고 있는지 설명

# Introduction

많은 실시간 데이터들이 우버의 데이터 센터에서 만들어진다.
그리고 이러한 데이터를 처리하는 것은 전방위적으로 영향을 미치고 상당히 중요하다.

아래의 세가지 영역에서 데이터 처리가 필요하다.

1. 메시지 플랫폼
2. 메세지들을 병렬 처리하는 스트림 프로세싱
3. OLAP (데이터 분석)

그리고 이 세가지 영역은 데이터 스케일링을 하는 데 있어 각각 세가지 고민거리를 안고 있다.

1. 데이터 범위 처리: 실시간 데이터량은 계속 증가하고, 여러 지역으로 나누어 데이터를 다루는데, 고객이 기대하는 범위 내에서 이러한 데이터 처리를 할 수 있어야한다.
2. 사용례 범위 처리: 다양한 영역에서의 비즈니스가 생기고, 그만큼 다양한 요구사항이 생긴다. 각 요구사항들을 해결하기 위하여 서로다른 우선순위가 있고, 그 우선순위에 따라 일처리를 진행해야 한다.
3. 사용자 처리: 다양한 이해관계자들은 기술적 기반이 있는 사람이 있고 없는 사람들도 있다. 이들 각각에 맞게 일처리를 해야한다.

결과적으로 하나의 통일된 플랫폼을 만들면서도, 여러 케이스를 포괄할 수 있어야한다.
이러한 고민거리를 해결하기위해 오픈 소스를 사용했다.
이러한 오픈소스 사용은 개발 속도, 비용 감소 측면에서 도움이 된다.

# Requirements

여러 방면으로 실시간 데이터를 사용하게 되는데, 각각은 여러 요구사항들이 있다.

1. 일관성
   재무적 대시보드 사용은 어떤 지역에서나 일정한 데이터를 요한다.
   지역과 관계없이 데이터 loss가 있어서는 안된다.

2. 사용 가능성
   언제든지 원할 때 데이터를 사용할 수 있어야한다.

3. 데이터 신선도
   초단위의 데이터 신선도가 요구된다.

4. 검색 시간
   검색에 너무 많은 시간이 소요되면 안된다.

5. 확장성
   계속해서 데이터들은 증가하게 되는데, 이를 따로 사용자가 프로세싱하는 데 시간을 들일 필요없이 매끄럽게 확장하는 것은 중요하다.

6. 비용
   높은 운영 효율으로 낮은 데이터 운용 비용을 이룩해야한다.

7. 유연성
   다양한 이해관계자 그룹에 맞게 선언적이고 프로그래머틱한 인터페이스를 제공해야한다.
   push-based, pull-based 모델 선택과 같이 상황에 따라서 다른 모델을 선택할 수 있다.

이 모든 요구사항을 보장하는 것은 불가능하다.
데이터 일관성이 있으면서도 데이터 신선도를 맞추는 것을 보장하긴 어렵다.
비지니스 영향을 최소화하기위하여, 상황에 맞게 우선순위를 정하는 것이 중요하다.

# Abstractions

실시간 데이터를 처리하는 논리적인 개념에서의 요소들 설명
**1) Storage**
일반적인 객체나, blob 스토리지 인터페이스. 데이터 일관성 보장

**2) Stream**
publish-subscribe interface 제공
데이터 읽고 쓰는데 지연이 있으면 안된다.
at least once와 파티션이 최소 조건

**3) Compute**
임의로 스트림 혹은 스토리지 레이어를 처리하는 것
스트림 처리시, 각각의 이벤트에 발생
스토리지 처리시, 일괄 처리
이는 스트림 혹은 스토리지 처리시 어떤 같거나 다른 기술을 사용할 수 있다는 점에서 중요하다.
같은 기술을 사용하게 된다면, 더 간단히 추상화를 시킬 수 있지만 실행하기는 더 복잡하다. 운영적 오버헤드가 발생간다.
반면에, 서로 다른 기술은 더 높은 레이어가 그에 맞게 각각 처리할 수 있게한다.

최소 조건: at least once semantics between data source and sink

**4) OLAP**
스트림이나 스토리지로부터 오는 데이터를 제한적으로 쿼리할 수 있다.
최소 조건: 서로 다른 데이터 소스로부터 데이터 처리 at least once semantics

**5) SQL**
OLAP를 기반으로 Full 쿼리, 처리 가능
Compute Layer와 함께 사용할시, sql문은 compute function에 컴파일된다.
OLAP layer와 함께 사용시, 제한된 쿼리위에서 추가적인 처리를 하게된다. ex) join문 사용
최소 조건: ANSI SQL에 가까운 SQL 언어 사용

**5) API**
스트림이나 compute function 을 구체화하는데 있어 SQL 인터페이스로는 충분하지 않은 경우

**6) Metadata**
메타데이터 관리하기위한 인터페이스
최소조건: 메타데이터 버전, 서로 양립 가능한지 체크

# System Overview

위의 요소들에 맞는 오픈 소스 시스템 설명.

### 스트리밍 스토리지를 위한 카프카

카프카는 유명한 분산 이벤트 스트리밍 시스템이다.
다른 것에 비하여 퍼포먼스 적으로, 운영 단순함, 생태계 등에서 최고라 선택하게 되었다.
우버에서는 매일 수조의 메세지와 페타바이트 데이터가 발생하는데, 카프카는 서로 다른 워크플로우에 이 데이터를 스트림한다.

1. Cluster Federation
   클러스터 에러 혹은 데이터 가용성을 향상시키기위해, 카프카 클러스터 셋업 처리를 하였다.
   어디에 클러스터링해야할지 고민할 필요가 없다.
   더불어 클러스터가 꽉 차면 스케일링도 할 수 있다.
   여러 서비스들이 많은데, 수동으로 유저를 옮길 필요도 없다.

2. Dead Letter queue
   몇몇 메세지가 처리되지않을 때가 있다. 카프카의 모델 아래선, 그를 없애거나 재시도 하는 방법이 있다.
   우버는 Dead Letter queue로 이를 해결했다.
   dead letter topic으로 옮겨 문제생긴 메세지를 유저가 처리하게 한다.

3. Consumer Proxy
   기존 카프카에서 Consumer Library를 제공해 client management를 돕지만, 우버는 너무 큰 회사이므로,
   여러 프로그래밍 언어 사용하는 상황도 보완하고, 여러 어플리케이션이 돌아가는 상황도 고려해야한다.
   따라서 우버는 프록시 레이어를 만들어 카프카에서 오는 메세지들을 소비하고 gRPC로 dispatch한다.
   이렇게 하면, 에러 핸들링이 수월하고, 기존 메세지 폴링 매커니즘에서 push-based로 전환이 가능하다. 높은 병렬성을 이룰 수 있다.

4. Cross-cluster Replication
   아무래도 큰 스케일로 카프카를 이용하다보니, 서로 다른 데이터 센터에서 여러 클러스터를 사용하게 되었다.
   이럴 경우, 전체적인 시점에서 다양한 사용례를 위해 데이터를 보아야 하고, 카프카가 많은 클러스터를 수용하고 데이터 센터의 failure를 대응하기 위해 복제되된다는 점에서,
   카프카 클러스터 복제가 필요하다.

uReplicator를 만들어 카프카 클러스터 사이를 오가는 복제물을 만들었다.
내부에는 리밸런싱 알고리즘이 있어, 리밸런싱 중에는 파티션 영향을 최소화한다. 또한 트래픽이 많아도 동적으로 로드를 조절할 수 있다.

더불어 자체적으로 감사하는 서비스도 만들었다. Chaperone이라는 서비스는 중요한 통계를 모아 비교하고 불일치가 발생하면 알람을 준다.

이러한 개선으로, 실시간으로 카프카 기반 위에서 스트리밍과 메세징 기능을 안정적으로 구현했다.

### 스트림 처리를 위한 Flink

모든 실시간 데이터를 카프카로 처리하기위해 우리는 스트림 처리 플랫폼을 플링크 기반으로 만들었다.
플링크는 high-throughput, low-latency를 자랑한다.
이 오픈소스는 많은 양의 업무를 처리하는 데 있어 충분히 안정적이고, 스케일하기가 좋다. 또, 사용하는 많은 사람들이 있다.

다른 것과 비교해봐도, 플링크가 우위에 있었다.

우버에서는, 고객들이 마주하는 프로덕을 유용하게 사용하고, 대시보드 용으로 플링크를 사용한다.
스트림 처리 로직은 SQL dialect나 API들로 표현된다.
SQL은 서로 다른 카테고리의 이해관계자들에게 사용된다. API는 더 세세히 처리하는 엔지니어용이다.

우버는 이 플링크에 두가지 개선을 만들었다.

1. SQL을 통한 분석 어플리케이션 생성
   FlinkSQL이라는 것을 만들었다.
   SQL프로세서가 쿼리들을 플링크 어플리케이션에 컴파일하고, 이해관계자들이 비지니스 로직만 신경쓰게끔 한다.
   내부적으로는, input SQL 쿼리를 플링크에 옮겨주는 로직을 만들었다.
   그러나 운영적으로 여러 어려움이 있었다.

- 자원 예측과 자동 스케일링
  할당된 메모리나 CPU와 같은 자원 설정은 중요하다.
  클러스터 이용을 최대화하기 위해, 지속적인 모니터링과 카비지 콜릭션, 오토 스케일링이 필요하다.
  플링크는 상태가 없기 때문이다.

- 활동 모니터링과 자동 실패 회복
  사용자는 플링크가 어떤 것을 하고 있는지 모르기 때문에, 플랫폼이 모니터해야한다.
  이를 위해 자동으로 이를 확인하는 컴포넌트를 만들었다.
  FlinkSQL은 프레스토와 같은 일괄처리 SQL시스템과는 다른 문법을 가지고 있다.
  이는 일괄처리하는 게 아니라, 지속으로 들어오는 데이터를 처리한다.

2. 배포, 관리, 운영을 위한 통일된 아키텍쳐 생성
   스트림 처리를 위하여 두개의 플랫폼을 만들었으므로, 하나의 통일된 아키텍처를 만들었다.

- 플랫폼 레이어
  비지니스 로직과 결합을 관리한다.
  특정 비지니스 로직을 기준이되는 플링크 잡으로 바꿔준다.
- 업무 관리 레이어
  플링크의 처리 사이클을 관리한다.
  통일된 API를 제공하고, 메타데이터 관리나 상태 체크포인트를 포함하는 업무 정보들을 유지한다.
  프록시 레이어로서 작용하기도 한다.
- 인프라 레이어
  물리적인 자원 제공, 스토리지와 compute 클러스터 포함

## OLAP를 위한 PINOT

Pinot은 낮은 처리시간을 자랑하는 OLAP 오픈소스 시스템이다. 컬럼 지향 DBMS로, 빠른 인덱싱을 제공한다.
scatter-gather-merge 접근으로 큰 테이블을 검색한다.
Pinot은 더 적은 메모리, 디스크 소모를 적게 하여 택했다.

이는 실시간 분석하는 데 큰 도움을 준다.
또한 많은 백서비스에서도 분석 쿼리 처리를 한다.

우버는 Pinot에 여러 기여를 했는데

1. Upsert 기능
   우버에 많이 사용되는 기능이다.
   실시간으로 OLAP 스토어에 업데이트가 가능하다.
   그러나 같은 메인 키에서 장소를 트래킹하는 것이 어려웠다.
   이를 해결하기위해 인풋 스트림을 여러 파티션으로 나누고, 처리를 위해 각 파티션을 한 노드에 분산했다.
   그 전에 쿼리 결과의 무결성을 위해 같은 노드에 같은 파티션을 두는 쿼리로 새로운 라우팅 전략을 제시했다.
