빅데이터의 등장은 전통적인 dbms로는 처리되지 않았다. 
많은 스토리지와 빅데이터 조작에 대하여 연구가 있었는데, Google MapReduce가 변화를 이끌었다. 
DBMS에 비하여, 심플하고 확장성이 있으며, 장애를 견딜 수 있었다. 그러나 효율성에 대하여는 갑론을박이 있었고, 프로그래밍을 하는데 좀 복잡했다. 
그 이후로 많은 것이 연구되었고, MapReduce 실행 오픈소스인 하둡이 이용되었다.

하둡의 성공 이후, 크게 세 갈래로 트렌드가 있었다. 
하나는 MapReduce 병렬 데이터 아이디어는 계승하되, 좀 더 나은 성능과 유연한 프로그래밍을 도입했다.
- Spark: 반복적이고 대화형 컴퓨팅
- Dryad: 그래프 커뮤니케이션, user 정의 작업

또 다른 트렌드는 DBMS의 오랜 역사의 장점을 취한 것이다
- data storage 레이어에서, NoSQL, Cassandra(확장성, 스키마가 없고 지속적인)
- sql-like 언어를 사용한다. Hive, Dremel.

남은 하나는 도메인 특정 문제에 집중한다. 머신 러닝이나 스트림 데이터 처리와 같이. 

이러한 빅데이터 생태계는 소프트웨어 스택들로 쌓여있다. 
낮은 레벨의 데이터베이스와 그에 기반한 데이터 프로세싱 엔진들을 포함한다.

로우레벨 데이터베이스는 데이터 유지와 낮은 지연에 사용된다. 
전통적인 것들에 비하여, 높은 확장성, 스키마 프리, 일관성, 높은 가용성, 간단한 API 를 자랑한다.

이들은 column store, document, graph, key-value store로 카테고리화 된다. 
- column store는 행 대신 열의 속성값을 저장한다.
- document 기반 데이터베이스는 데이터를 document로 저장한다. 
- graph 기반 데이터베이스는 그래프 구조를 저장한다. (노드와 간선)
- key-value 데이터베이스는 데이터를 key-value로 저장한다. 

데이터베이스를 나눌 또 다른 영역은 data format이다.
구조, 반구조, 구조 없는 세 가지로 나뉜다. 
- 구조없는: 텍스트, 비디오
- 구조: 각 요소가 다양한 결합으로 접근되는
- 반구조: 구조적으로 구성되지는 않지만 추가적인 정보가 있다.

MongoDB, Cassandra는 반구조와 구조 없는 데이터를 지원한다. 

데이터베이스 꼭대기는 데이터 처리 레이어가 있다. 
Dremel, AsterixDB는 높은 수준의 SQL-like 언어를 사용한다. 
다른 것들은 MapReduce-like 사용한다.

인풋에 따라서, 현재 빅데이터 처리를 배치, 스트림, 그래프와 머신러닝으로 나눈다. 
- Batch는 큰 데이터셋을 처리하는 데 효율적이다. 데이터를 모으고, 분배하고 처리한다.
- Stream은 속도가 중요하다. 데이터는 효율성을 위하여 배치하는 것은 허용되지 않는다.
- Graph는 그래프 데이터 구조를 시행, 맵리듀스 데이터 병렬성에 더해 모델 병렬성을 수행한다.
  - ML 문제의 부분적 해결을 지원한다.
  
이 논문에서는 data processing 레이어에 대해 집중할 것이다. 
맵리듀스를 소개하고, DBMS와 비교하고, 최적화하는 것에 대해 이야기할 것이다. 그리고 이 처리 시스템 평가할 벤치마크에 대해서도 이야기할 것이다

## 기본 맵 리듀스 프레임워크
MapReduce란, 빅데이터를 분산 데이터 센터 시스템에서 처리할 큰 스케일의 프로그래밍 모델이다. 
심플하고 분산 프로그램을 돌리는 데 있어 디테일한 부분을 추상화한다. 병렬, 장애 견디는, 데이터 분산과 로드밸런싱과 같은.

### MapReduce Framework
Map과 Reduce, 두 단계가 있다. key-value 짝으로 진행된다. 
Map 단계에서는 사용자가 작성한 함수와 input 짝들을 분산 머신에 사상한다. 
이 단계에서 중간 결과물- key-value 짝이 생성된다.
그리고 Reduce 단계에서는 이 중간 단계의 짝을 하나의 결과로 줄여낸다.

1) 분산 파일 시스템은 인풋 data를 동일한 크기로 파티션한다. 그리고 결함 허용을 위하여 각기 다른 머신에 복사본을 저장한다. 
2) MapReduce 라이브러리가 마스터와 많은 worker copies를 생성해낸다. 마스터는 worker copies에 일을 전달하고 임무 수행을 조율한다. 지역성을 위해, 마스터는 인풋 데이터에 일치하는 복사본을 포함하는 머신에 Map task를 스케줄링한다.
3) Map worker는 로컬 인풋 파티션을 스캔하고, 중간 키 페어를 만들어낸다. 결과는 로컬 디스크에 저장되고, R개의 파티션으로 나뉜다. 이 중간 단계의 결과는 마스터에게 알려진다. 
4) Reduce worker는 중간 결과를 로컬 디스크로부터 읽고, 정렬한다. 같은 키로 정렬하고 마지막 결과를 생성한다.
5) master는 모든 worker를 주기적으로 ping 한다. 만약 Map, Reduce worker가 장애가 나면, 다른 worker에게 일이 할당된다.
6) 모든 일이 끝나면, 유저 프로그램이 깨워진다. 

이 맵리듀스는 몇몇 훌륭한 장점이 있다.
- 심플함: 프로그래머가 굳이 병렬 혹은 분산 시스템에 대한 경험이 없어도 된다. 비교적으로 시스템 설정이나 설치가 직접적이다.
- 결함 허용: 미세한 실패를 다룰 수 있고, 잃는 작업량을 최소화 할 수 있고, 재시작할 필요가 없다. 
- 유연함: 인풋 데이터는 포맷이 필요가 없다.
- 독립성: 스토리지 시스템에서 독립적이다. 
- 확장성: 수천의 프로세서로 확장 가능하다.

### DBMS와 MapReduce 비교
MapReduce 이전에, 병렬 DBMS가 데이터 분석을 하는 데 사용됐다. 
기본적으로 MapReduce 작업이 DBMS와 똑같이 쓰여질 수 있기 때문에, 맵리듀스는 많은 의심을 샀었다.
이는 StoneBraker외 몇명이 DBMS와 MapReduce를 비교하며 가라앉았다.
그에 따르면 MapReduce는 DBMS의 보완재다. DBMS가 효율을 목표로 하면 MapReduce는 결함을 허용하고 확장성이 있다. 

둘 사이 다른 점은 
1. 비효율: MapReduce는 DBMS에 비해 로딩은 빠르지만, 업무 실행시간은 느리다. 그 이유는 Hadoop의 시작하는 데 걸리는 시간 때문이다. DBMS는 로딩할 때 사전 파싱을 진행하지만, MapReduce는 그렇게 할 수 없다. 
또한, DBMS는 몇십년 간 개발되어온 compression, column storage, 복잡한 병렬 알고리즘과 같은 발전된 기술이 있다. MapReduce는 동기화를 위하여 control message들을 보내는데, 이것이 오버헤드를 높인다.
2. 재사용성: MapReduce는 스키마나 인덱스를 사용하지 않는다. 프로그래머들은 인풋 파일 구조를 파싱하거나, 속도를 빨리하기 위하여 인덱스를 맵과 리듀스 프로그램에서 실행해야한다.
게다가, 간단하고 일반적인 작업 실행을 제공해야한다. (selection, projection). 그러한 커스텀 코드는 재사용되거나 다른 이들에게 공유되기 어렵고, 에러를 발생시키기 쉽다. 
그러나, DBMS는 내장된 스키마와 인덱스가 있다. 많은 오퍼레이터에게 높은 수준의 추상화를 제공한다. 사용자들은 그냥 간단하게 시스템에 무엇을 원하는지만 지정하면 된다. 

결론적으로, MapReduce가 DBMS보다 선호되는 부분들은: 
1. 일회성 분석: 인덱싱이나 재배열을 할 필요가 없는 데이터들
2. 복잡한 분석: HTML 다큐먼트로부터 나오는 링크를 추출하는 것과같은 SQL에서는 쉽게 하기 복잡한 작업들을 잘 할 수 있다. 
3. 빠른 시작: 맵류드스 실행은 설정하기 쉽다.
4. 제한된 예산: 오픈소스다.

## 맵리듀스 변수들과 확장
### 서로 다른 데이터 플로우 지원
- 반복작업: I/O 대역폭을 낭비할 수 있고, 몇 종료 조건은 그 자체로 맵리듀스 작업이고, 맵리듀스 잡은 시리얼하게 끝내져야 한다는 성능적 문제들이 반복 작업의 이슈들이다.
  - 이는 반복인터페이스 추가하거나, 캐싱하거나, 태스크 스케줄러를 수정하는 등으로 반복작업을 지원할 수 있다. 
  - 맵리듀스 자체로는 반복을 지원하지않는다.
  - HaLoop, iMapReduce, iHadoop, Twister, MapIterativeReduce
- online, streaming: batch 기반으로 실행되는데, 
  - 즉 모든 인풋과 아웃풋이 다음 스테이지에 의해 소비되기 이전에 로컬 파일에 구체화되어있어야 한다. 
  - 이는 간단하고 결함 허용 매커니즘 실행을 허용한다. 
  - 그러나, 이러한 블로킹은 성능 하락을 가져와 온라인이나 스트림 처리가 어렵게한다. 
  - MapReduce Online, DEDUCE

## 데이터 접근 최적화
런타임에 파싱하기 때문에 MapReduce는 DBMS에 비하여 비효율적이다. 
그를 극복하기 위하여 인덱스 구조, 컬럼 스토리지 등을 사용한다.
### Index 지원
Hadoop++은 아무 프레임워크를 바꾸지 않고는 성능을 개선했다. 
- 트로이 인덱스 
  - 데이터를 인덱스된 부분으로 구성한다. 데이터.인덱스.헤더와 푸터로!
  - 데이터 로딩 타임에 이 인덱스가 생성되고, 쿼리 시간에는 아무 지장이 없다. 
  - 만들어지는 중에 정렬된다. 
- 트로이 조인
  - 인풋 데이터가 로딩 시간에 함께 파티션될 수 있다고 가정한다. 
  - 자세히는, 다양한 인풋 릴레이션은 같은 파티셔닝 함수를 적용한다. 
  - 결과적으로, 조인 작업은 각각의 노드안에서 지역적으로 처리될 수 있다. 
- 트로이 레이아웃
  - 내부 데이터를 위해, 속성들이 빈번하게 접근되는 경우 그루핑되고 집합된다.
  - HAIL은 업로드 파이프라인을 바꿔서(HDFS의) 서로 다른 클러스터 인덱스를 만들어낸다. 

### 컬럼 스토리지
분산 파일 시스템에서 테이블 데이터 조직을 결정할 데이터 배치구조를 만드는 것이 시스템 효율에 중요 요소다.
- RCFile
  - 하둡에서 실행된다. 
  - 이 안의 테이블은 횡으로 행 그룹을 나눈다. 이는 종으로 나뉜다.
  - 컬럼 기준 데이터 압축이 일어난다. 그러면서 lazy하게 압축을 풀어낸다.
  - 유연한 행 사이즈를 허용한다. 
  - 각 HDFS 블록들에서, RCFile은 기본 행 단위들로 레코드를 조직한다.
  - 모든 행 그룹은 같은 사이즈를 가지고있다.
  - 그 사이즈에 따라서, HDFS 블록은 하나 혹은 여러개의 행 그룹을 가진다. 행그룹은 세 개의 섹션으로 나뉜다
    - 하나는 시작하는 지점을 표한 싱크 마커,
    - metadata header도 있다.
    - 테이블 데이터 섹션이다.
- Llama
  - 행 방향 열 방향 데이터베이스 시스템의 특징을 결합한 관리 시스템. 
  - 컬럼방향 포맷인 CFile을 제안. 각 파일은 블록 인덱스를 가지고 있다. 
  - 동시 조인 제안. 이는 대부분의 작업들을 맵 단계에 밀어넣어 효과적으로 맵리듀스 잡을 줄이는 것이다. 

### 관계 데이터 배치
데이터 배치 정책은 좋은 로드 밸런스를 하기 위함이다. 이는 한개의 파일로는 잘 돌아가는데, 여러개의 파일로는 어렵다.
그 이유는 관련 데이터를 함께 배치하는 기능이 없기 때문이다. 

- coHadoop: 이를 극복하기 위하여 만들어졌다. 

## 자동 파라미터 튜닝
맵리듀스같은 데이터 프로세싱 시스템을 이용하여 좋은 성능을 내려면, 많은 설정 파라미터들이 조정되어야한다. 
이에 대한 전문지식이 없는 실무자를 위하여, 자동으로 파라미터를 튜닝해주는 작업에 대해서 이야기한다.

### 시스템 튜닝
맵리듀스가 실행될 때, 온라인으로 프로필을 수집하는 프로파일러가 나왔다. 이를 계속 수집하며 맵리듀스를 그에 맞게 조정한다.
비용 기반 옵티마이저에 필요한 세분화된 비용 추정에 What-if 엔진이 사용된다.

- Starfish: 프로파일러와 What-if 엔진을 기반으로, starfish가 나왔다. 
  - 기본적으로, 데이터 매니저를 둔다.
  - 좋은 구성 설정을 찾기 위해 비용 기반 옵티마이저는 What-if 엔진을 적절하게 호출하여 고차원 구성 매개변수 설정 공간을 효율적으로 열거하고 검색한
- Stubby
  - 비용 기반 최적화

### I/O 튜닝
빅데이터는 주로 데이터 집약적이다. 그래서 I/O는 시스템 보틀넥이 되기 쉽다.
분산 파일 시스템과 I/O 미들웨어 레이어는 모두 최적화를 제공한다. 그러나, 최적의 파라미터 조합은 어플리케이션에 의존적이다. 
제일 좋은 파라미터 조합을 고르는 것은 알고리즘 개발자에게 큰 짐을 가져다 줄 것이다. 
- 자동 튜닝 중에 소스 코드를 바꾸지 않기 위하여, H5Tuner는 HDF5 호출을 동적으로 가로채고 최적화 매개변수를 병렬 I/O 호출에 주입하도록 설계되었다.