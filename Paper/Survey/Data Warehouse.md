## 10.1145/248603.248616


Data Warehouse: "주제 중심적", "결합된", "시간에 따라 변하는", "비휘발성"
- 이는 조직의 운영 데이터베이스와는 다르다. 
  - OLTP는 수백 메가바이트에서 기가바이트 정도되는 데이터베이스로, 구조적이고, 트랜잭션이 짧고, 원자적이고 분리되어야한다. 컨플릭트를 최소화한다.
  - 그러나 Data warehouse는 의견 확정을 목표로한다. 
    - 디테일하고 개별 자료보다는 뭉뚱그려진, 요약된 데이터가 더 중요하다.
    - 양도 훨씬 크다. 쿼리 이용률이 더 중요하다.

- 복잡한 분석과 시각화를 위하여, 다차원적으로 모델링되어있다. 

- Data warehouse가 필요했던 이유가 있다
  - 다차원적 데이터 모델은 특별한 데이터 구조, 접근 방법과 실행방법들이 OLTP와는 다른 것을 요구한다.
  - 운영 데이터베이스는 정제되어있음에 반해서, OLAP의 결과는 예상치 못한 것일 것이다.
  - 운영데이터에 없는 데이터가 요구된다 (역사적인..)

- 서버의 종류가 관계 DBMS의 연장선에서 만들어진 ROLAP일수도, 혹은 바로 특별한 데이터 구조로 바로 인입된 MOLAP일수도 있다.

## 아키텍처
- 일단 데이터 로딩, 일시적 리프레싱, 더 느린 스토리지로의 load 진행
- 메인 data warehouse와 여러개의 데이터 마트가 있다. 이들은 하나 혹은 여러개의 warehouse server에 의해서 만들어지고 관리된다.
  그리고, 프론트엔드 툴을 통하여 다차원적인 view를 보여준다. 
- metadata 관리하는, 모니터링하는 레포가 있다.

## 백엔드 툴과 기능
- data cleaning
  - data warehouse는 결정을 내리는 데 사용되므로, 데이터가 정확해야한다. 그래서 이를 위한 툴이 필요하다.
    - 그러나 많은 곳에서 많은 데이터가 연관되므로, 에러가 있을 확률이 높다. 
    - 일관되지않은 설명과 field 길이, 값 할당 등에 data cleaning이 필요하다.
  - data cleaning tool과 관련된 세 가지가 있다.
    - data migration: 간단한 변형 룰 사용 가능하다.
    - data scrubbing: 도메인 특정 정보를 사용한다. 
    - data auditing: 규칙과 관계를 발견한다. 
- load
  - 데이터 추출, cleaning transforming까지 한 뒤에, load 되어야한다. 
  - 추가적인 프로세싱이 필요하다: 집계, integrity 제약 확인, 정렬, 요약 등
    - batch load 기능이 이를 위해 사용된다. 
  - 또한 상태를 감독하고, 로드를 취소하거나 미루는 것도 필요하다.
  - 파이프라인되고 구분된 병렬이 사용된다. 
    - 긴 batch 트랜잭션이 새로운 데이터베이스를 만드는 동안 사용될 때, 현 데이터베이스는 쿼리를 감당 가능하고, 트랜잭션이 이뤄지면, 다른 것으로 대체된다.
  - 그러나 너무 긴 batch 트랜잭션은 또 문제를 낳는다. 
- Refresh
  - 원천 데이터 변경시 다른 데이터도 바뀌는 것. 
  - 언제 어떻게 refresh를 할지가 고민.
  - Refresh 기술은 원천 데이터의 특성과 데이터베이스 서버의 능력에 따라 달라진다. 
    - 보통은 점진적으로 refresh한다.
    - 이를 위해 서버 복제를 한다. 
    - data shipping: table이 원천 데이터베이스의 remote snapshot같은 것으로 간주된다.. 
    - transaction shipping: 정규 트랜잭션 로그가 사용된다. 복제된 테이블의 변화를 알아채고 복제 서버에 보내진다. 
      - 트랜잭션 로그 접근 표준 api가 없으므로, 서로 다른 vendor에서의 dbms를 쉬이 이동하며 이용하기 어렵다.
  - Refresh cycle을 잘 설정해야 많은 데이터가 점진적인 로드 기능을 넘어서지 않는다.
  
## 개념적 모델과 프론트엔드 툴
다차원적인 view가 선호된다. 보통 그 기준은 숫자로 구성된 수단이다. (판매, 예산, 수입..)
여러개의 부분들 (city, product name..)들이 함쳐진 것이 하나의 수단 (판매)을 만들어낸다.
각 디멘션은 여러개의 속성으로 묘사된다. 

또, 각 수단에 대한 집계도 개념적 모델에서 중요하다.

- 프론트엔드 툴
  - 스프레드시트가 많이 사용됨
  - 그럼에도 불구하고, 관리된 쿼리 환경을 수단으로 하는 전통적인 분석 환경을 대체하지는 않았다. 

## 데이터베이스 디자인 방법론
다차원적인 데이터 모델은, 기본적으로는 MOLAP이지만, ROLAP 서버가 요청하면 그를 릴레이션에 매핑해야한다.
- 이를 위해 기본적으로는 star schema라는 것을 사용한다.
  - 하나의 fact table과 각 디멘션 별 싱글 테이블.
  - 각 튜플은 포인터를 포함한다. 이는 각 디멘션이 다차원적인 조정을 제공하도록 한다. 
  - 각 디멘션 테이블은 디멘션 속성에 일치하는 컬럼을 포함한다. 
  - 명시적으로 속성 위계를 제공하지는 않는다. 
- snowflake schema는 star schema에서 명시적으로 위계가 표현되게끔 한다. 
  - 이는 디멘션 테이블을 정규화해서 할 수 있는 것이다.
  - 그러나, denormalized 구조가 디멘션 검색에는 더 적절하다. 

## Warehouse server
쿼리를 효율적으로 처리하기위하여, 효율적인 접근 방법과 쿼리 프로세싱 기술이 필요하지만, 몇가지를 해결해야한다.
- 불필요한 구조를 (인덱스, materialized views) 가지고 있다는 것
- 존재하는 index, materialized views를 효과적으로 사용하는 것
- 병렬성이 필요하다.

### 인덱스 구조와 그의 사용
- 싱글테이블: 비트맵 인덱스
- 여러개의 테이블: 조인 인덱스

### Materialized views와 그의 사용
- 어떤 뷰를 구체화할지 정하고, 
- 쿼리에 응답하기위해 구체화된 뷰를 만들고
- 효율적으로 뷰를 업데이트한다. 

## 메타데이터와 warehouse 관리
다양한 메타데이터 종류가 관리된다.
메타데이터 리포지토리는 warehouse와 관련된 모든 메타데이터를 쌓고 관리하는 데 사용된다. 

warehouse 시스템을 만들고 관리하는 것은 어렵다. 많은 종류의 툴들이 사용가능하다. 
최근에는 데이터를 인입하는 extract-scrup-transform-load-refresh 과정의 workflow를 관리하는 툴이 고려된다. 
이는 특정 이벤트가 발생할 때 일시적으로 launch될 수 있다. 또한, 성공적으로 과정을 끝내게 한다.

## Research Issues
- Data cleaning: 이질적인 데이터 통합을 연상시키는 문제. 하지만 데이터의 일정하지않은 것이 문제다. 스키마의 문제라기보다는.
- 물리적 디자인: 백엔드서버와 ROLAP와 같은 미들웨어 사이 쿼리 엔진 기능 분리, 인덱스 셀렉션과 data partitioning문제.
- data warehouse 관리: indices, materialized view의 로드와 refresh issue 실패와 관련해서 더 많은 리서치 필요. materialized view 성능에 대한 연구 필요.